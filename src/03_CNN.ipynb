{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "## Download & Extract the dataset"
      ],
      "metadata": {
        "id": "MmrrovM8lXzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxxgPVBmlKWk",
        "outputId": "ee171b47-1282-4a24-d4ec-ec9322c7c556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./cifar10.tgz\n"
          ]
        }
      ],
      "source": [
        "# Dowload the dataset\n",
        "from torchvision.datasets.utils import download_url\n",
        "\n",
        "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url, '.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract from archive\n",
        "import tarfile\n",
        "\n",
        "data_dir = './data'\n",
        "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
        "    tar.extractall(path=data_dir)"
      ],
      "metadata": {
        "id": "vr8ZVfxXll0i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore the dataset"
      ],
      "metadata": {
        "id": "INnEXQaGme2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "data_dir = data_dir + \"/cifar10\"\n",
        "\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"/train\")\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDp1QlHIlpr0",
        "outputId": "4b002b9d-c72f-4eb7-c5ab-6f3737a1f448"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'train']\n",
            "['automobile', 'dog', 'horse', 'ship', 'airplane', 'cat', 'frog', 'bird', 'deer', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in classes:\n",
        "    print(f\"{c:10s} (train): {len(os.listdir(data_dir + '/train/' + c))}\")\n",
        "    print(f\"{c:10s} ( test): {len(os.listdir(data_dir + '/test/' + c))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wx9ZB6omFS0",
        "outputId": "90a3bebb-41b7-4ebf-c1d8-092c83d59682"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "automobile (train): 5000\n",
            "automobile ( test): 1000\n",
            "dog        (train): 5000\n",
            "dog        ( test): 1000\n",
            "horse      (train): 5000\n",
            "horse      ( test): 1000\n",
            "ship       (train): 5000\n",
            "ship       ( test): 1000\n",
            "airplane   (train): 5000\n",
            "airplane   ( test): 1000\n",
            "cat        (train): 5000\n",
            "cat        ( test): 1000\n",
            "frog       (train): 5000\n",
            "frog       ( test): 1000\n",
            "bird       (train): 5000\n",
            "bird       ( test): 1000\n",
            "deer       (train): 5000\n",
            "deer       ( test): 1000\n",
            "truck      (train): 5000\n",
            "truck      ( test): 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer the images to Tensors"
      ],
      "metadata": {
        "id": "XbhpTgRHnrUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "dataset_train = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
        "\n",
        "print(f\"Total size of the dataset: {len(dataset_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3OMm7FzmwoA",
        "outputId": "34b6e957-e673-49d1-acbc-304b25352bda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the dataset: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RGB 32x32 pixels per image; 3 (channel) * 32 (width) * 32 (height)\n",
        "img, label = dataset_train[0]\n",
        "print(img.shape, label)\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krnYrjo7oH0U",
        "outputId": "f3f0b32c-4e13-4dd8-b114-fa55f3a1bb72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32]) 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7922, 0.7922, 0.8000,  ..., 0.8118, 0.8039, 0.7961],\n",
              "         [0.8078, 0.8078, 0.8118,  ..., 0.8235, 0.8157, 0.8078],\n",
              "         [0.8235, 0.8275, 0.8314,  ..., 0.8392, 0.8314, 0.8235],\n",
              "         ...,\n",
              "         [0.8549, 0.8235, 0.7608,  ..., 0.9529, 0.9569, 0.9529],\n",
              "         [0.8588, 0.8510, 0.8471,  ..., 0.9451, 0.9451, 0.9451],\n",
              "         [0.8510, 0.8471, 0.8510,  ..., 0.9373, 0.9373, 0.9412]],\n",
              "\n",
              "        [[0.8000, 0.8000, 0.8078,  ..., 0.8157, 0.8078, 0.8000],\n",
              "         [0.8157, 0.8157, 0.8196,  ..., 0.8275, 0.8196, 0.8118],\n",
              "         [0.8314, 0.8353, 0.8392,  ..., 0.8392, 0.8353, 0.8275],\n",
              "         ...,\n",
              "         [0.8510, 0.8196, 0.7608,  ..., 0.9490, 0.9490, 0.9529],\n",
              "         [0.8549, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
              "         [0.8471, 0.8431, 0.8471,  ..., 0.9333, 0.9333, 0.9333]],\n",
              "\n",
              "        [[0.7804, 0.7804, 0.7882,  ..., 0.7843, 0.7804, 0.7765],\n",
              "         [0.7961, 0.7961, 0.8000,  ..., 0.8039, 0.7961, 0.7882],\n",
              "         [0.8118, 0.8157, 0.8235,  ..., 0.8235, 0.8157, 0.8078],\n",
              "         ...,\n",
              "         [0.8706, 0.8392, 0.7765,  ..., 0.9686, 0.9686, 0.9686],\n",
              "         [0.8745, 0.8667, 0.8627,  ..., 0.9608, 0.9608, 0.9608],\n",
              "         [0.8667, 0.8627, 0.8667,  ..., 0.9529, 0.9529, 0.9529]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of the classes\n",
        "print(dataset_train.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecJ-wl7Eoep3",
        "outputId": "7f7dc5a5-b425-447a-bbeb-5b878991033e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "val_size = int(len(dataset_train)*.1)\n",
        "train_size = len(dataset_train) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset_train, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJzzRma2oo9L",
        "outputId": "3de5ac3b-5ae6-4420-84eb-c219fc9ef5fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "batch_size=128\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size*2)"
      ],
      "metadata": {
        "id": "ofpvIezMqiyt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data\n",
        "for images, labels in train_loader:\n",
        "    print('images.shape:', images.shape)\n",
        "    break\n",
        "\n",
        "# Validation data\n",
        "for images, labels in val_loader:\n",
        "    print('images.shape:', images.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUvhOOQzrCY6",
        "outputId": "2ff7306f-7c39-4218-f523-a9a93e3b5f7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images.shape: torch.Size([128, 3, 32, 32])\n",
            "images.shape: torch.Size([256, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "## Define the network"
      ],
      "metadata": {
        "id": "k09oTlkvrnZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.batchn1 = nn.BatchNorm2d(32)\n",
        "        self.batchn2 = nn.BatchNorm2d(64)\n",
        "        self.batchn3 = nn.BatchNorm2d(128)\n",
        "        self.batchn4 = nn.BatchNorm2d(128)\n",
        "        self.batchn5 = nn.BatchNorm2d(256)\n",
        "        self.batchn6 = nn.BatchNorm2d(256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):                           # Output shape\n",
        "        x = self.relu(self.batchn1(self.conv1(x)))  #  32 * 32 * 32\n",
        "        x = self.relu(self.batchn2(self.conv2(x)))  #  64 * 32 * 32\n",
        "        x = self.maxpool(x)                         #  64 * 16 * 16\n",
        "\n",
        "        x = self.relu(self.batchn3(self.conv3(x)))  # 128 * 16 * 16\n",
        "        x = self.relu(self.batchn4(self.conv4(x)))  # 128 * 16 * 16\n",
        "        x = self.maxpool(x)                         # 128 *  8 *  8\n",
        "\n",
        "        x = self.relu(self.batchn5(self.conv5(x)))  # 256 *  8 *  8\n",
        "        x = self.relu(self.batchn6(self.conv6(x)))  # 256 *  8 *  8\n",
        "        x = self.maxpool(x)                         # 256 *  4 *  4\n",
        "\n",
        "        x = self.flatten(x)                         # 4096 = 256*4*4\n",
        "        x = self.relu(self.fc1(x))                  # 1024\n",
        "        x = self.relu(self.fc2(x))                  # 512\n",
        "        x = self.fc3(x)                             # 10\n",
        "        return x"
      ],
      "metadata": {
        "id": "pddcz1cerNv1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SimpleCNN().to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHq7wG65vqh4",
        "outputId": "9053301d-8ed2-42d1-c8a9-1099fc02019a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
            "          Flatten-22                 [-1, 4096]               0\n",
            "           Linear-23                 [-1, 1024]       4,195,328\n",
            "             ReLU-24                 [-1, 1024]               0\n",
            "           Linear-25                  [-1, 512]         524,800\n",
            "             ReLU-26                  [-1, 512]               0\n",
            "           Linear-27                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 5,853,066\n",
            "Trainable params: 5,853,066\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.77\n",
            "Params size (MB): 22.33\n",
            "Estimated Total Size (MB): 27.11\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function & Optimizer\n",
        "from torch import optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "9oaL7gqZu-yg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the training & validation"
      ],
      "metadata": {
        "id": "5E3KDN6Zxt6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    running_loss_train = 0.0\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_train += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    running_loss_val = 0.0\n",
        "    running_acc_val = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss_val += loss.item()\n",
        "            probabilities = F.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            running_acc_val += torch.sum(preds == labels).item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1:2d}/{epochs:2d}], TRN Loss: {running_loss_train / len(train_loader):.4f}, VLD Loss: {running_loss_val / len(val_loader):.4f}, VLD Acc: {running_acc_val / len(val_ds):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii_ph6Ohv0se",
        "outputId": "6f37f58d-530e-4974-d620-0eb5d9cf8de9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [ 1/ 5], TRN Loss: 1.3744, VLD Loss: 1.0734, VLD Acc: 0.6132\n",
            "Epoch [ 2/ 5], TRN Loss: 0.8694, VLD Loss: 0.7707, VLD Acc: 0.7308\n",
            "Epoch [ 3/ 5], TRN Loss: 0.6686, VLD Loss: 0.7834, VLD Acc: 0.7292\n",
            "Epoch [ 4/ 5], TRN Loss: 0.5413, VLD Loss: 0.5879, VLD Acc: 0.7982\n",
            "Epoch [ 5/ 5], TRN Loss: 0.4394, VLD Loss: 0.6344, VLD Acc: 0.7930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "kQW-aSGB9RxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(ImageFolder(data_dir+'/test', transform=ToTensor()), batch_size*2)"
      ],
      "metadata": {
        "id": "n7A3HKyZ-UFI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_test = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        acc_test += torch.sum(preds == labels).item()\n",
        "print(f'Test Acc: {acc_test / len(test_loader.dataset)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7e_xE48-WdP",
        "outputId": "09cd43e5-887f-4718-cc26-a4428434136c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 78.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save or Load the model parameters (optional)"
      ],
      "metadata": {
        "id": "6wAWjPVr9EDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'simple_cnn.pth')"
      ],
      "metadata": {
        "id": "0sFkrA378CpA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN().to(device)\n",
        "model.load_state_dict(torch.load('simple_cnn.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMdIXIE79Hko",
        "outputId": "f8426263-a144-495b-ec11-300fd11c61e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-f03323192659>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('simple_cnn.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "- https://www.kaggle.com/code/shadabhussain/cifar-10-cnn-using-pytorch\n",
        "- https://medium.com/@sergioalves94/deep-learning-in-pytorch-with-cifar-10-dataset-858b504a6b54"
      ],
      "metadata": {
        "id": "3CX2CIbIDzrh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_F-GI5HJD103"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}